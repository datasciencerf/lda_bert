{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from LDA_BERT.model import model\n",
    "from LDA_BERT.text_processing.sentence_splitting import split_into_sentences\n",
    "from LDA_BERT.text_processing import is_hyperlink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Sample Data (Self Posts from Mattress Subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It was Me not the Mattress. I went through a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIL about Purple mattresses.... Holy balls.......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just received my new Tempur-Pedic LUXEbreeze s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I work for Mattress Firm in operations in a ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't like the Purple 2.... Been sleeping on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  It was Me not the Mattress. I went through a l...\n",
       "1  TIL about Purple mattresses.... Holy balls.......\n",
       "2  Just received my new Tempur-Pedic LUXEbreeze s...\n",
       "3  I work for Mattress Firm in operations in a ve...\n",
       "4  I don't like the Purple 2.... Been sleeping on..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../examples/examples_data/matt.csv')\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data and get it prepared for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>doc_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It was Me not the Mattress.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I went through a lot of mattresses over a numb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My lower back pain always seemed to come back.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turns out I have something called chronic pelv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is a bizarre problem that doctors don't tot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent  doc_no\n",
       "0                        It was Me not the Mattress.       0\n",
       "1  I went through a lot of mattresses over a numb...       0\n",
       "2     My lower back pain always seemed to come back.       0\n",
       "3  Turns out I have something called chronic pelv...       0\n",
       "4  It is a bizarre problem that doctors don't tot...       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_data = []\n",
    "for k, text in enumerate(df.text.values):\n",
    "    text = ' '.join([w for w in text.split() if not is_hyperlink(w)])\n",
    "    for sent in split_into_sentences(text):\n",
    "        sent_data.append({'sent': sent, 'doc_no': k})\n",
    "sent_df = pd.DataFrame(sent_data)\n",
    "sent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12403\n",
      "Preprocessing raw texts ...\n",
      "Preprocessing raw texts. Done!\n",
      "10920\n"
     ]
    }
   ],
   "source": [
    "rws = sent_df.sent.values\n",
    "print(len(rws))\n",
    "sentences, token_lists, idx_in = model.preprocess(rws)\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering embeddings ...\n",
      "Getting vector representations for LDA ...\n",
      "Getting vector representations for LDA. Done!\n",
      "Getting vector representations for BERT ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ad4afa85374c7ebca28cecb5ff52da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=1365.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting vector representations for BERT. Done!\n",
      "Fitting Autoencoder ...\n",
      "Fitting Autoencoder Done!\n",
      "Clustering embeddings. Done!\n"
     ]
    }
   ],
   "source": [
    "tm = model.Topic_Model(k=10, method='LDA_BERT')\n",
    "tm.fit(sentences, token_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate LSA Topic Model as Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import randomized_svd\n",
    "tfidf = TfidfVectorizer(min_df=3, max_df=0.1,\n",
    "                        stop_words='english', ngram_range=(1,3),\n",
    "                        sublinear_tf=True)\n",
    "tfidf_m = tfidf.fit_transform(sentences)\n",
    "U, S, V = randomized_svd(tfidf_m.T, 15, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m looking to get a memory foam mattress.\n",
      "_____________\n",
      "The first was a Silk+Snow, which was my very first memory foam (lived with standard ol' innersprings all my life).\n",
      "_____________\n",
      "Memory foam is not soft enough.\n",
      "_____________\n",
      "I have a bed in the box memory foam mattress.\n",
      "_____________\n",
      "We have never had a memory foam mattress.\n",
      "_____________\n",
      "I'm thinking of just diying a memory foam mattress.\n",
      "_____________\n",
      "Memory Foam after a year?\n",
      "_____________\n",
      "The bed is much better than my old memory foam mattress but still heats up.\n",
      "_____________\n",
      "What memory foam should we look at?\n",
      "_____________\n",
      "Would it work with memory foam?\n",
      "_____________\n",
      "Memory foam way too hot.\n",
      "_____________\n",
      "Is it worth getting a memory foam topper for my sunken 14 year old memory foam mattress or should I just focus on a new mattress?\n",
      "_____________\n",
      "So please, if you buy a memory foam mattress, be weary of fiberglass!\n",
      "_____________\n",
      "So I had this memory foam mattress from Lucid for a few years.\n",
      "_____________\n",
      "I sleep hot and don't love memory foam, so I think I'm looking at spring mattresses.\n",
      "_____________\n"
     ]
    }
   ],
   "source": [
    "for k in V.T[:,0].argsort()[-15:][::-1]:\n",
    "    print(sent_df.sent.values[idx_in[k]])\n",
    "    print('_____________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1989, 10119, 10069,    66,  5414,  8667,  6671,   441,  2438,\n",
       "        4087], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.T[:,0].argsort()[-10:][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans to generate Topic Clusters (Note they are not very good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "cm = KMeans(10)\n",
    "clusters = cm.fit_predict(tm.vec['LDA_BERT'])\n",
    "cluster_idx = {k: np.array(idx_in)[np.where(clusters==k)] for k in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you have a Sleep Sherpa store near you, you can try out nearly all the online beds in that one store & order from there too- same price & everything.\n",
      "-----------------------------------------\n",
      "I now know most of those are sponsored reviews and outright fabrications.\n",
      "-----------------------------------------\n",
      "So last week I started really researching mattresses.\n",
      "-----------------------------------------\n",
      "I spent a lot of time here in this sub, specifically, to learn more about mattresses and to avoid disinformation.\n",
      "-----------------------------------------\n",
      "I just received it two days ago.\n",
      "-----------------------------------------\n",
      "In those two nights I have slept better than I have in years.\n",
      "-----------------------------------------\n",
      "I wake up without pain and I haven’t woken up with the sheets sticking to me due to sweat.\n",
      "-----------------------------------------\n",
      "Edit: does anyone use a cotton mattress pad or moisture barrier on their LUXEbreeze, or does that make the cooling less effective?\n",
      "-----------------------------------------\n",
      "Now, time to sleep.\n",
      "-----------------------------------------\n",
      "After revisiting the store and telling the salesman about our experience he admitted that the purple mattresses are the worst.\n",
      "-----------------------------------------\n",
      "I can't find the info online.\n",
      "-----------------------------------------\n",
      "So maybe they are trying to pull a fast one on me?\n",
      "-----------------------------------------\n",
      "After trying both for a couple hours in store I went with the Black Ice.\n",
      "-----------------------------------------\n",
      "I am outside the 120 days but they are going to let me do it anyways.\n",
      "-----------------------------------------\n",
      "Under the same financing, with all paid amounts credited.\n",
      "-----------------------------------------\n",
      "Purple mattress delayed 3 weeks.\n",
      "-----------------------------------------\n",
      "I was super excited to get my purple mattress in around a week for shipping but I get this email stating there’ll be a 3 week delay.\n",
      "-----------------------------------------\n",
      "There’s an option to refund for 50$ and get a mattress with a purple topper but I didn’t realize how real and often the shipping delays would occur at puprple\n",
      "-----------------------------------------\n",
      "I guess something in the middle ground.\n",
      "-----------------------------------------\n",
      "He is not night time trained.\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sent in sent_df.sent.values[cluster_idx[1]][:20]:\n",
    "    print(sent)\n",
    "    print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar Document Extraction (This is where LDA_BERT seems to shine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = euclidean_distances(tm.vec['LDA_BERT_FULL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1988, 3971, 4540, 4324, 2291, 8781, 4325, 5587, 4530, 8945],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[1988].argsort()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m about 6’4 290 and I’m a side sleeper.\n",
      "---------------------------\n",
      "I’m 6’2 230 and I mainly sleep on my back, and sometimes on the side.\n",
      "---------------------------\n",
      "I’m a back and side sleeper and 5’7”/130 pounds.\n",
      "---------------------------\n",
      "Notes about us - I’m 5’3” 130lb and a side/stomach sleeper.\n",
      "---------------------------\n",
      "I am mostly a back sleeper but spend some time on my side.\n",
      "---------------------------\n",
      "* I’m a side sleeper.\n",
      "---------------------------\n",
      "I am a side sleeper.\n",
      "---------------------------\n",
      "I am a side sleeper.\n",
      "---------------------------\n",
      "I am a side sleeper.\n",
      "---------------------------\n",
      "I am a side sleeper.\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "for k in dist[528].argsort()[:10]:\n",
    "    print(sent_df.sent.values[idx_in[k]])\n",
    "    print('---------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "U2, S2, V2 = randomized_svd(tm.vec['LDA_BERT_FULL'].T, 15, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my parents just never saw it as a priority to replace it so i never saw it as a priority to find comfort\n",
      "_____________\n",
      "i absolutely hated the topper and couldnt sleep on it after 2 nights of trying\n",
      "_____________\n",
      "i never received any emails from bear regarding this and it was especially surprising given that it had already gone out for delivery\n",
      "_____________\n",
      "well i contacted the company a couple weeks ago by email because no one is picking up the phone and they havent responded\n",
      "_____________\n",
      "also because of the pandemic i obviously can’t go to a store to test it out\n",
      "_____________\n",
      "not even going to deal with their warranty department on it because they just make it a pain the arse\n",
      "_____________\n",
      "after doing some more research i saw that they have terrible delivery and customer service so im canceling that order\n",
      "_____________\n",
      "i havent had the chance to try any out on stores because of the virus\n",
      "_____________\n",
      "the place doesn’t do returns or exchanges due to the virus\n",
      "_____________\n",
      "they dont have a phone number to call as they mislead you in the faq section of their website\n",
      "_____________\n",
      "i really dont want to go into a store right now\n",
      "_____________\n",
      "rember they dont answer their emails either\n",
      "_____________\n",
      "i long ago decided not to buy from any company that had standalone stores as they have to add rent and other expenses on top and i dont want to pay for that\n",
      "_____________\n",
      "they stand me up 2 different times waste 2 days out of my life and then dont even call me to reschedule and go out of their way to make sure that its not possible to contact a human being\n",
      "_____________\n",
      "the trouble is it seems to have been discontinued and i don’t have any of the specs for it so i don’t even know where to start\n",
      "_____________\n"
     ]
    }
   ],
   "source": [
    "for k in V2.T[:,2].argsort()[-15:]:\n",
    "    print(sentences[k])\n",
    "    print('_____________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
